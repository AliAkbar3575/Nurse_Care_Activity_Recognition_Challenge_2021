{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle, scipy, random, time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.style.use('fivethirtyeight')\n",
    "\n",
    "#import all necessary libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import catboost, lightgbm, xgboost\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>start</th>\n",
       "      <th>finish</th>\n",
       "      <th>label</th>\n",
       "      <th>wave_appro_x_1</th>\n",
       "      <th>wave_details_x_1</th>\n",
       "      <th>wave_appro_x_2</th>\n",
       "      <th>wave_details_x_2</th>\n",
       "      <th>wave_appro_x_3</th>\n",
       "      <th>wave_details_x_3</th>\n",
       "      <th>...</th>\n",
       "      <th>jerk_y_z_covar</th>\n",
       "      <th>gra_x_y_covar</th>\n",
       "      <th>gra_x_z_covar</th>\n",
       "      <th>gra_y_z_covar</th>\n",
       "      <th>body_x_y_covar</th>\n",
       "      <th>body_x_z_covar</th>\n",
       "      <th>body_y_z_covar</th>\n",
       "      <th>jerk_body_x_y_covar</th>\n",
       "      <th>jerk_body_x_z_covar</th>\n",
       "      <th>jerk_body_y_z_covar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>2018-05-02 00:57:13.026000+00:00</td>\n",
       "      <td>2018-05-02 00:57:17.976000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>29.575164</td>\n",
       "      <td>-0.074384</td>\n",
       "      <td>29.671432</td>\n",
       "      <td>0.113113</td>\n",
       "      <td>30.699674</td>\n",
       "      <td>0.124029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004382</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-3.839830e-06</td>\n",
       "      <td>1.996606e-05</td>\n",
       "      <td>3.428637e-08</td>\n",
       "      <td>-2.192912e-07</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2018-05-02 00:57:15.026000+00:00</td>\n",
       "      <td>2018-05-02 00:57:19.976000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>31.223481</td>\n",
       "      <td>0.045835</td>\n",
       "      <td>31.093535</td>\n",
       "      <td>-0.333277</td>\n",
       "      <td>30.619536</td>\n",
       "      <td>0.157530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008945</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.423978e-08</td>\n",
       "      <td>-6.619763e-04</td>\n",
       "      <td>-2.515746e-05</td>\n",
       "      <td>-3.416138e-05</td>\n",
       "      <td>0.055622</td>\n",
       "      <td>-0.012920</td>\n",
       "      <td>-0.016635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2018-05-02 00:57:17.026000+00:00</td>\n",
       "      <td>2018-05-02 00:57:21.976000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>30.414322</td>\n",
       "      <td>-0.001846</td>\n",
       "      <td>30.334898</td>\n",
       "      <td>-0.302524</td>\n",
       "      <td>30.927157</td>\n",
       "      <td>0.352237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.851753e-06</td>\n",
       "      <td>2.054279e-04</td>\n",
       "      <td>-2.511390e-05</td>\n",
       "      <td>-1.920471e-05</td>\n",
       "      <td>0.114467</td>\n",
       "      <td>-0.012324</td>\n",
       "      <td>-0.011097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2018-05-02 00:57:19.026000+00:00</td>\n",
       "      <td>2018-05-02 00:57:23.976000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>29.984322</td>\n",
       "      <td>-0.013482</td>\n",
       "      <td>30.010792</td>\n",
       "      <td>0.054172</td>\n",
       "      <td>30.644166</td>\n",
       "      <td>0.088239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4.399206e-06</td>\n",
       "      <td>-1.843823e-04</td>\n",
       "      <td>6.526186e-06</td>\n",
       "      <td>9.306546e-06</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>2018-05-02 00:57:21.026000+00:00</td>\n",
       "      <td>2018-05-02 00:57:25.976000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>30.414296</td>\n",
       "      <td>-0.012291</td>\n",
       "      <td>30.317877</td>\n",
       "      <td>-0.400519</td>\n",
       "      <td>31.197177</td>\n",
       "      <td>0.485815</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003977</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.824796e-06</td>\n",
       "      <td>-3.911691e-04</td>\n",
       "      <td>-1.410523e-05</td>\n",
       "      <td>1.495776e-05</td>\n",
       "      <td>-0.015768</td>\n",
       "      <td>-0.007513</td>\n",
       "      <td>-0.004358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130345</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-13 23:41:23.002000+00:00</td>\n",
       "      <td>2018-06-13 23:41:27.952000+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>-103.089534</td>\n",
       "      <td>-0.015961</td>\n",
       "      <td>-103.087421</td>\n",
       "      <td>-0.044936</td>\n",
       "      <td>-102.760547</td>\n",
       "      <td>0.101208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.030971e-06</td>\n",
       "      <td>3.080432e-04</td>\n",
       "      <td>1.179615e-05</td>\n",
       "      <td>6.513816e-06</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130346</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-13 23:41:25.002000+00:00</td>\n",
       "      <td>2018-06-13 23:41:29.952000+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>-102.676474</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>-102.716918</td>\n",
       "      <td>-0.109757</td>\n",
       "      <td>-102.868489</td>\n",
       "      <td>0.052805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.633280e-06</td>\n",
       "      <td>1.399728e-04</td>\n",
       "      <td>5.067773e-05</td>\n",
       "      <td>5.074720e-06</td>\n",
       "      <td>0.024472</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>0.001254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130347</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-13 23:41:27.002000+00:00</td>\n",
       "      <td>2018-06-13 23:41:31.952000+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>-103.240176</td>\n",
       "      <td>-0.009438</td>\n",
       "      <td>-103.191811</td>\n",
       "      <td>0.149265</td>\n",
       "      <td>-103.088257</td>\n",
       "      <td>-0.092804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001985</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>8.933175e-06</td>\n",
       "      <td>5.636844e-04</td>\n",
       "      <td>-7.243138e-06</td>\n",
       "      <td>5.646384e-05</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>-0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130348</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-13 23:41:29.002000+00:00</td>\n",
       "      <td>2018-06-13 23:41:33.952000+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>-103.156734</td>\n",
       "      <td>-0.011518</td>\n",
       "      <td>-103.157193</td>\n",
       "      <td>-0.039833</td>\n",
       "      <td>-102.799585</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002847</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>2.131977e-05</td>\n",
       "      <td>1.480436e-04</td>\n",
       "      <td>2.760928e-05</td>\n",
       "      <td>-3.917918e-05</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>-0.004434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130349</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-13 23:41:31.002000+00:00</td>\n",
       "      <td>2018-06-13 23:41:35.952000+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>-102.720346</td>\n",
       "      <td>0.016359</td>\n",
       "      <td>-102.774813</td>\n",
       "      <td>-0.149137</td>\n",
       "      <td>-102.810109</td>\n",
       "      <td>0.106674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>4.022966e-05</td>\n",
       "      <td>5.396877e-07</td>\n",
       "      <td>1.029982e-07</td>\n",
       "      <td>-2.607396e-07</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130349 rows × 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       User_id                             start  \\\n",
       "0           12  2018-05-02 00:57:13.026000+00:00   \n",
       "1           12  2018-05-02 00:57:15.026000+00:00   \n",
       "2           12  2018-05-02 00:57:17.026000+00:00   \n",
       "3           12  2018-05-02 00:57:19.026000+00:00   \n",
       "4           12  2018-05-02 00:57:21.026000+00:00   \n",
       "...        ...                               ...   \n",
       "130345       4  2018-06-13 23:41:23.002000+00:00   \n",
       "130346       4  2018-06-13 23:41:25.002000+00:00   \n",
       "130347       4  2018-06-13 23:41:27.002000+00:00   \n",
       "130348       4  2018-06-13 23:41:29.002000+00:00   \n",
       "130349       4  2018-06-13 23:41:31.002000+00:00   \n",
       "\n",
       "                                  finish  label  wave_appro_x_1  \\\n",
       "0       2018-05-02 00:57:17.976000+00:00      1       29.575164   \n",
       "1       2018-05-02 00:57:19.976000+00:00      1       31.223481   \n",
       "2       2018-05-02 00:57:21.976000+00:00      1       30.414322   \n",
       "3       2018-05-02 00:57:23.976000+00:00      1       29.984322   \n",
       "4       2018-05-02 00:57:25.976000+00:00      1       30.414296   \n",
       "...                                  ...    ...             ...   \n",
       "130345  2018-06-13 23:41:27.952000+00:00     28     -103.089534   \n",
       "130346  2018-06-13 23:41:29.952000+00:00     28     -102.676474   \n",
       "130347  2018-06-13 23:41:31.952000+00:00     28     -103.240176   \n",
       "130348  2018-06-13 23:41:33.952000+00:00     28     -103.156734   \n",
       "130349  2018-06-13 23:41:35.952000+00:00     28     -102.720346   \n",
       "\n",
       "        wave_details_x_1  wave_appro_x_2  wave_details_x_2  wave_appro_x_3  \\\n",
       "0              -0.074384       29.671432          0.113113       30.699674   \n",
       "1               0.045835       31.093535         -0.333277       30.619536   \n",
       "2              -0.001846       30.334898         -0.302524       30.927157   \n",
       "3              -0.013482       30.010792          0.054172       30.644166   \n",
       "4              -0.012291       30.317877         -0.400519       31.197177   \n",
       "...                  ...             ...               ...             ...   \n",
       "130345         -0.015961     -103.087421         -0.044936     -102.760547   \n",
       "130346          0.012444     -102.716918         -0.109757     -102.868489   \n",
       "130347         -0.009438     -103.191811          0.149265     -103.088257   \n",
       "130348         -0.011518     -103.157193         -0.039833     -102.799585   \n",
       "130349          0.016359     -102.774813         -0.149137     -102.810109   \n",
       "\n",
       "        wave_details_x_3  ...  jerk_y_z_covar  gra_x_y_covar  gra_x_z_covar  \\\n",
       "0               0.124029  ...       -0.004382      -0.000645       0.000002   \n",
       "1               0.157530  ...       -0.008945      -0.000416       0.000005   \n",
       "2               0.352237  ...       -0.005040      -0.000241       0.000008   \n",
       "3               0.088239  ...       -0.003277      -0.000116       0.000008   \n",
       "4               0.485815  ...       -0.003977      -0.000035       0.000007   \n",
       "...                  ...  ...             ...            ...            ...   \n",
       "130345          0.101208  ...       -0.000122      -0.000017       0.000002   \n",
       "130346          0.052805  ...       -0.000036      -0.000029       0.000007   \n",
       "130347         -0.092804  ...       -0.001985      -0.000047       0.000017   \n",
       "130348          0.103600  ...       -0.002847      -0.000071       0.000033   \n",
       "130349          0.106674  ...       -0.000120      -0.000098       0.000056   \n",
       "\n",
       "        gra_y_z_covar  body_x_y_covar  body_x_z_covar  body_y_z_covar  \\\n",
       "0       -3.839830e-06    1.996606e-05    3.428637e-08   -2.192912e-07   \n",
       "1        5.423978e-08   -6.619763e-04   -2.515746e-05   -3.416138e-05   \n",
       "2        2.851753e-06    2.054279e-04   -2.511390e-05   -1.920471e-05   \n",
       "3        4.399206e-06   -1.843823e-04    6.526186e-06    9.306546e-06   \n",
       "4        4.824796e-06   -3.911691e-04   -1.410523e-05    1.495776e-05   \n",
       "...               ...             ...             ...             ...   \n",
       "130345   1.030971e-06    3.080432e-04    1.179615e-05    6.513816e-06   \n",
       "130346   2.633280e-06    1.399728e-04    5.067773e-05    5.074720e-06   \n",
       "130347   8.933175e-06    5.636844e-04   -7.243138e-06    5.646384e-05   \n",
       "130348   2.131977e-05    1.480436e-04    2.760928e-05   -3.917918e-05   \n",
       "130349   4.022966e-05    5.396877e-07    1.029982e-07   -2.607396e-07   \n",
       "\n",
       "        jerk_body_x_y_covar  jerk_body_x_z_covar  jerk_body_y_z_covar  \n",
       "0                  0.000406             0.000094            -0.000040  \n",
       "1                  0.055622            -0.012920            -0.016635  \n",
       "2                  0.114467            -0.012324            -0.011097  \n",
       "3                  0.038879            -0.004096             0.000005  \n",
       "4                 -0.015768            -0.007513            -0.004358  \n",
       "...                     ...                  ...                  ...  \n",
       "130345             0.008815             0.000514             0.001227  \n",
       "130346             0.024472            -0.000123             0.001254  \n",
       "130347             0.016200            -0.001231            -0.001264  \n",
       "130348            -0.002155             0.000596            -0.004434  \n",
       "130349             0.000012             0.000024            -0.000006  \n",
       "\n",
       "[130349 rows x 529 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pickle.load(open('feature1.pickle', 'rb'))\n",
    "df['label'] = df['label'].astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(n_features):\n",
    "    \n",
    "    etc = ExtraTreesClassifier(n_estimators=50, max_depth=13, n_jobs=-1, criterion='entropy').fit(df.drop(columns=['User_id', 'start', 'finish', 'label']), df['label'])\n",
    "    rf = RandomForestClassifier(n_estimators=60, max_depth=13, n_jobs=-1, criterion='entropy').fit(df.drop(columns=['User_id', 'start', 'finish', 'label']), df['label'])\n",
    "\n",
    "    cols = df.drop(columns=['User_id', 'start', 'finish', 'label']).columns\n",
    "    etc_fi = pd.Series(etc.feature_importances_, index=cols)\n",
    "    rf_fi = pd.Series(rf.feature_importances_, index=cols)\n",
    "\n",
    "    treefi = (etc_fi.sort_index() + rf_fi.sort_index())/2\n",
    "    treefi = treefi.sort_values()\n",
    "    return treefi.tail(n_features).index\n",
    "\n",
    "remained_columns = feature_selection(280)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remained_columns = pickle.load(open('remained_columns320.pkl', 'rb'))\n",
    "len(remained_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\AntonioEnv\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\User\\.conda\\envs\\AntonioEnv\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(130349, 322)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['User_id', 'label'] + list(remained_columns)]\n",
    "df.dropna(inplace=True)\n",
    "# df.drop(columns=['User_id'], inplace=True)\n",
    "df['label'] = df['label'].astype('int')\n",
    "# df.drop(columns=list(del_cols), inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## under and over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling(df):\n",
    "    labels = [4,2,14]\n",
    "    n_rows = [33000, 24000, 8000]\n",
    "\n",
    "    for label, rows in zip(labels, n_rows):\n",
    "        ind = df[df['label']==label].index\n",
    "        r = random.sample(range(0, len(ind)), rows)\n",
    "        deleted = ind[r]\n",
    "        df.drop(deleted, axis=0, inplace=True)\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(df):\n",
    "    # !pip install imblearn\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    os = RandomOverSampler(random_state=25)\n",
    "    labels1 = df['label'].value_counts().head(11).index\n",
    "    \n",
    "    df1 = df[df['label'].isin(labels1)]\n",
    "    labels2 = df['label'].value_counts().tail(13).index\n",
    "    df2 = df[df['label'].isin(labels2)]\n",
    "    \n",
    "    X1, y1 = df1.drop(columns=['label']), df1['label']\n",
    "    X2, y2 = os.fit_resample(df2.drop(columns=['label']), df2['label'])\n",
    "\n",
    "    print(f'after undersampling(topclass data) : {X1.shape, y1.shape}')\n",
    "    print(f'after oversampling(underclass data) : {X2.shape, y2.shape}')\n",
    "\n",
    "    X = pd.concat([X1, X2], axis=0)\n",
    "    y = pd.concat([y1, y2], axis=0)\n",
    "\n",
    "    print(f'shape of my training data : {X.shape, y.shape}')\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65349, 321)\n",
      "after undersampling(topclass data) : ((63324, 320), (63324,))\n",
      "after oversampling(underclass data) : ((10998, 320), (10998,))\n",
      "shape of my training data : ((74322, 320), (74322,))\n",
      "(74322, 320) (74322,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff = under_sampling(df.drop(columns=['User_id']))\n",
    "X, y = over_sampling(dff)\n",
    "\n",
    "dff = pd.concat([X,y], axis=1)\n",
    "\n",
    "dff = dff.sample(frac=1).reset_index(drop=True)\n",
    "X_train = dff.drop(columns=['label'])\n",
    "y_train = dff['label']\n",
    "print(X_train.shape, y_train.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     10677\n",
       "2     10645\n",
       "14    10119\n",
       "12     9766\n",
       "9      6408\n",
       "10     5025\n",
       "7      2812\n",
       "16     2447\n",
       "13     2440\n",
       "19     1719\n",
       "11     1266\n",
       "3       846\n",
       "5       846\n",
       "6       846\n",
       "8       846\n",
       "28      846\n",
       "25      846\n",
       "15      846\n",
       "17      846\n",
       "18      846\n",
       "20      846\n",
       "22      846\n",
       "24      846\n",
       "1       846\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    ini = time.time()\n",
    "    clf = model.fit(X_train,y_train)\n",
    "    cv_score = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "#     print(f'model info for {model_name.upper()} classifier : ')\n",
    "    print('---------------------------------------')\n",
    "    print(f'Cross-validation : {cv_score}')\n",
    "    print(f'mean : {np.mean(cv_score)}')\n",
    "#     print(f'median : {np.median(cv_score)}')\n",
    "#     print(f'std : {np.std(cv_score)}\\n')\n",
    "    print(f'shape of input data : {X_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Cross-validation : [0.87350835 0.87719059 0.87397709 0.87602291 0.87370431]\n",
      "mean : 0.874880650587247\n",
      "shape of input data : (73322, 280)\n"
     ]
    }
   ],
   "source": [
    "train_model(RandomForestClassifier(n_estimators=600, max_depth=13, n_jobs=-1, criterion='entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Cross-validation : [0.87241732 0.87241732 0.87397709 0.87697763 0.87343153]\n",
      "mean : 0.8738441784691722\n",
      "shape of input data : (73322, 280)\n"
     ]
    }
   ],
   "source": [
    "train_model(lightgbm.LGBMClassifier(n_estimators=200, reg_lambda=0.01, reg_alpha=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98910, 322)\n",
      "(98910, 320) (98910,)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df['User_id'].isin([2,3,4,5,6,12,17])]\n",
    "X_train, y_train = train_df.drop(columns=['User_id', 'label']), train_df['label']\n",
    "print(train_df.shape)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31439, 322)\n",
      "(31439, 320) (31439,)\n"
     ]
    }
   ],
   "source": [
    "val_df = df[~df['User_id'].isin([2,3,4,5,6,12,17])]\n",
    "X_val, y_val = val_df.drop(columns=['User_id', 'label']), val_df['label']\n",
    "print(val_df.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     40535\n",
       "2     17851\n",
       "14    11087\n",
       "12     9766\n",
       "9      5141\n",
       "10     4538\n",
       "7      2812\n",
       "16     2447\n",
       "13     2412\n",
       "1       772\n",
       "19      363\n",
       "5       182\n",
       "17      154\n",
       "6       148\n",
       "22      134\n",
       "3       126\n",
       "28      106\n",
       "18       89\n",
       "8        82\n",
       "24       57\n",
       "15       55\n",
       "11       35\n",
       "25       17\n",
       "20        1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['User_id'])\n",
    "val_df = val_df.drop(columns=['User_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## under and over sampling for user_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling1(df):\n",
    "    labels = [4,2]\n",
    "    n_rows = [28000, 5000]\n",
    "\n",
    "    for label, rows in zip(labels, n_rows):\n",
    "        ind = df[df['label']==label].index\n",
    "        r = random.sample(range(0, len(ind)), rows)\n",
    "        deleted = ind[r]\n",
    "        df.drop(deleted, axis=0, inplace=True)\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "def over_sampling1(df):\n",
    "    # !pip install imblearn\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    os = RandomOverSampler(random_state=42)\n",
    "    labels1 = df['label'].value_counts().head(9).index\n",
    "    \n",
    "    df1 = df[df['label'].isin(labels1)]\n",
    "    labels2 = df['label'].value_counts().tail(15).index\n",
    "    df2 = df[df['label'].isin(labels2)]\n",
    "    \n",
    "    X1, y1 = df1.drop(columns=['label']), df1['label']\n",
    "    X2, y2 = os.fit_resample(df2.drop(columns=['label']), df2['label'])\n",
    "\n",
    "    print(f'after undersampling(topclass data) : {X1.shape, y1.shape}')\n",
    "    print(f'after oversampling(underclass data) : {X2.shape, y2.shape}')\n",
    "\n",
    "    X = pd.concat([X1, X2], axis=0)\n",
    "    y = pd.concat([y1, y2], axis=0)\n",
    "\n",
    "    print(f'shape of my training data : {X.shape, y.shape}')\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65910, 321)\n",
      "after undersampling(topclass data) : ((63589, 320), (63589,))\n",
      "after oversampling(underclass data) : ((11580, 320), (11580,))\n",
      "shape of my training data : ((75169, 320), (75169,))\n",
      "(75169, 320) (75169,)\n"
     ]
    }
   ],
   "source": [
    "dff = under_sampling1(train_df)\n",
    "X, y = over_sampling1(train_df)\n",
    "\n",
    "dff = pd.concat([X,y], axis=1)\n",
    "dff = dff.sample(frac=1).reset_index(drop=True)\n",
    "X = dff.drop(columns=['label'])\n",
    "y = dff['label']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     12851\n",
       "4     12535\n",
       "14    11087\n",
       "12     9766\n",
       "9      5141\n",
       "10     4538\n",
       "7      2812\n",
       "16     2447\n",
       "13     2412\n",
       "3       772\n",
       "5       772\n",
       "6       772\n",
       "8       772\n",
       "28      772\n",
       "11      772\n",
       "25      772\n",
       "15      772\n",
       "17      772\n",
       "18      772\n",
       "19      772\n",
       "20      772\n",
       "22      772\n",
       "24      772\n",
       "1       772\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model selection and hyperparameters tuning (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time required : 8.246294085184733 minutes\n",
      "train score : 0.9832111641767218\n",
      "validation score : 0.4858615095899997\n"
     ]
    }
   ],
   "source": [
    "# def lgbm_model(lmbda):\n",
    "# lambda=0.01, alpha=0.001\n",
    "ini = time.time()\n",
    "clf = lightgbm.LGBMClassifier(n_estimators=200, reg_lambda=0.01, reg_alpha=0.001).fit(X, y)\n",
    "final = time.time()\n",
    "print(f'time required : {(final-ini)/60} minutes')\n",
    "print(f'train score : {clf.score(X, y)}')\n",
    "print(f'validation score : {clf.score(X_val, y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.1 : \n",
      "time required : 24.767437314987184 minutes\n",
      "train score : 0.9305097874463364\n",
      "validation score : 0.3422818791946309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def lgbm_model(lmbda):\n",
    "ini = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=600, max_depth=13, n_jobs=-1, criterion='entropy').fit(X, y)\n",
    "# RandomForestClassifier(n_estimators=600, max_depth=13, n_jobs=-1, criterion='entropy')\n",
    "print(f'alpha={lmbda} : ')\n",
    "final = time.time()\n",
    "print(f'time required : {(final-ini)/60} minutes')\n",
    "print(f'train score : {clf.score(X, y)}')\n",
    "print(f'validation score : {clf.score(X_val, y_val)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more methods of feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual info classif\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "m_info = mutual_info_classif(X,y)\n",
    "\n",
    "data = pd.Series(m_info, index=df.columns)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova test\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "anova = f_classif(X, y)\n",
    "anova, _ = anova\n",
    "\n",
    "a = pd.Series(anova, index=X.columns).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi_square test\n",
    "\n",
    "chi2, _ = scipy.stats.chisquare(df.drop(columns=['label']))\n",
    "b = pd.Series(chi2, index=df.drop(columns=['label']).columns).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using high variance (the columns have lower variance, are not so significant for our model's performance)\n",
    "\n",
    "var = []\n",
    "for col in X.columns:\n",
    "    var.append((np.std(X[col]))**2)\n",
    "var_thres = pd.Series(var, index=X.columns).sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
